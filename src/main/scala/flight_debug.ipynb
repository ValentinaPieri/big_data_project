{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2867fd65945315d",
   "metadata": {},
   "source": [
    "# Flight Delay Analysis\n",
    "\n",
    "**Objective**:\n",
    "- Group by **Airline** to classify them as **Good** / **Average** / **Bad** based on the average departure delay.\n",
    "- Join the classification back to the original dataset to tag each flight with its airline’s class.\n",
    "- Group by **Route** (Origin→Dest) and **Class** to count the number of flights and uncover patterns.\n",
    "\n",
    "There are **two** Spark pipelines in Scala:\n",
    "1. **Non‑optimized version**\n",
    "2. **Optimized version**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c30ddf3a60ae4c",
   "metadata": {},
   "source": [
    "## 1. Setup Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce24977b0480c3e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:29:08.179641Z",
     "start_time": "2025-06-04T20:28:44.821933Z"
    }
   },
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import org.apache.spark.broadcast.Broadcast\n",
    "import org.apache.spark.rdd.RDD\n",
    "import java.io.{File, PrintWriter}\n",
    "import java.util.Calendar"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.148.1:4040\n",
       "SparkContext available as 'sc' (version = 3.5.1, master = local[*], app id = local-1749068934338)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.sql.functions._\r\n",
       "import org.apache.spark.sql.DataFrame\r\n",
       "import org.apache.spark.storage.StorageLevel\r\n",
       "import org.apache.spark.broadcast.Broadcast\r\n",
       "import org.apache.spark.rdd.RDD\r\n",
       "import java.io.{File, PrintWriter}\r\n",
       "import java.util.Calendar\r\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6ecaaae008ff1247",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:29:14.560382Z",
     "start_time": "2025-06-04T20:29:10.864319Z"
    }
   },
   "source": [
    "val spark = SparkSession.builder()\n",
    "    .appName(\"FlightDelayAnalysis\")\n",
    "    .getOrCreate()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@6a998ea9\r\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "9b80d5b8806fcffa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:29:19.735156Z",
     "start_time": "2025-06-04T20:29:18.145314Z"
    }
   },
   "source": [
    "val path_to_output = \"../../../src/main/outputs/\"\n",
    "val path_to_samples = \"../../../datasets/samples/\"\n",
    "\n",
    "val path_2019_ds = path_to_samples + \"Combined_Flights_2019_sample.csv\"\n",
    "val path_2020_ds = path_to_samples + \"Combined_Flights_2020_sample.csv\"\n",
    "val path_2021_ds = path_to_samples + \"Combined_Flights_2021_sample.csv\"\n",
    "val path_2022_ds = path_to_samples + \"Combined_Flights_2022_sample.csv\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_to_output: String = ../../../src/main/outputs/\r\n",
       "path_to_samples: String = ../../../datasets/samples/\r\n",
       "path_2019_ds: String = ../../../datasets/samples/Combined_Flights_2019_sample.csv\r\n",
       "path_2020_ds: String = ../../../datasets/samples/Combined_Flights_2020_sample.csv\r\n",
       "path_2021_ds: String = ../../../datasets/samples/Combined_Flights_2021_sample.csv\r\n",
       "path_2022_ds: String = ../../../datasets/samples/Combined_Flights_2022_sample.csv\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "ce8f4320eb858c37",
   "metadata": {},
   "source": [
    "## 2. Load & Inspect a Sample for Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ba2ac747dff0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "val sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "id": "de6af39a5fcaa595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:29:34.611841Z",
     "start_time": "2025-06-04T20:29:33.078372Z"
    }
   },
   "source": [
    "def logJobExecution(startTime: Long, jobName: String, outputPath: String): Unit = {\n",
    "\n",
    "    val endTime = System.currentTimeMillis()\n",
    "    val duration = endTime - startTime\n",
    "    val dateTime = Calendar.getInstance().getTime()\n",
    "\n",
    "    println(s\"[$dateTime] Job '$jobName' completed in $duration ms.\")\n",
    "\n",
    "    val writer = new PrintWriter(new File(outputPath))\n",
    "    writer.write(s\"[$dateTime] Job '$jobName' completed in $duration ms.\\n\")\n",
    "    writer.close()\n",
    "}"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logJobExecution: (startTime: Long, jobName: String, outputPath: String)Unit\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "4797cecb68d918ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:29:38.566470Z",
     "start_time": "2025-06-04T20:29:36.918316Z"
    }
   },
   "source": [
    "def parseFlights(row: String) = {\n",
    "    \n",
    "    def getInt(s: String): Int = {\n",
    "        val str = if (s == null) \"\" else s.trim\n",
    "        if (str.matches(\"-?\\\\d+\")) str.toInt else 0\n",
    "    }\n",
    "\n",
    "    def getDouble(s: String): Double = {\n",
    "        val str = if (s == null) \"\" else s.trim\n",
    "        if (str.matches(\"-?\\\\d+(\\\\.\\\\d+)?\")) str.toDouble else 0.0\n",
    "    }\n",
    "\n",
    "    def getBoolean(s: String): Boolean =\n",
    "        Option(s).map(_.trim.toLowerCase).contains(\"true\")\n",
    "\n",
    "    val columns = row.split(\",\", -1).map(_.trim.stripPrefix(\"\\\"\").stripSuffix(\"\\\"\"))\n",
    "\n",
    "    val flightDate = columns(0)\n",
    "    val airline = columns(1)\n",
    "    val origin = columns(2)\n",
    "    val dest = columns(3)\n",
    "    val cancelled = getBoolean(columns(4))\n",
    "    val diverted = getBoolean(columns(5))\n",
    "    val depTime = getInt(columns(7))\n",
    "    val depDelay = getDouble(columns(9))\n",
    "    val airTime = getDouble(columns(12))\n",
    "    val year = getInt(columns(16))\n",
    "    val month = getInt(columns(17))\n",
    "\n",
    "    (flightDate, airline, origin, dest, cancelled, diverted, depTime, depDelay, airTime, year, month)\n",
    "}"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parseFlights: (row: String)(String, String, String, String, Boolean, Boolean, Int, Double, Double, Int, Int)\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "2e4032536d37d7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:29:41.525602Z",
     "start_time": "2025-06-04T20:29:40.694599Z"
    }
   },
   "source": [
    "def loadYear(path: String) = {\n",
    "    val raw = sc.textFile(path)\n",
    "    val header = raw.first()\n",
    "    raw.filter(_ != header)\n",
    "}"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadYear: (path: String)org.apache.spark.rdd.RDD[String]\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "66e28e2fcb934e1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:29:47.919250Z",
     "start_time": "2025-06-04T20:29:43.580830Z"
    }
   },
   "source": [
    "val raw2019 = loadYear(path_2019_ds)\n",
    "val raw2020 = loadYear(path_2020_ds)\n",
    "val raw2021 = loadYear(path_2021_ds)\n",
    "val raw2022 = loadYear(path_2022_ds)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw2019: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at filter at <console>:37\r\n",
       "raw2020: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[5] at filter at <console>:37\r\n",
       "raw2021: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[8] at filter at <console>:37\r\n",
       "raw2022: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[11] at filter at <console>:37\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "88c39701757f355f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:29:51.965437Z",
     "start_time": "2025-06-04T20:29:49.992911Z"
    }
   },
   "source": [
    "val flights2019 = raw2019.map(x => parseFlights(x))\n",
    "val flights2020 = raw2020.map(x => parseFlights(x))\n",
    "val flights2021 = raw2021.map(x => parseFlights(x))\n",
    "val flights2022 = raw2022.map(x => parseFlights(x))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flights2019: org.apache.spark.rdd.RDD[(String, String, String, String, Boolean, Boolean, Int, Double, Double, Int, Int)] = MapPartitionsRDD[12] at map at <console>:38\r\n",
       "flights2020: org.apache.spark.rdd.RDD[(String, String, String, String, Boolean, Boolean, Int, Double, Double, Int, Int)] = MapPartitionsRDD[13] at map at <console>:39\r\n",
       "flights2021: org.apache.spark.rdd.RDD[(String, String, String, String, Boolean, Boolean, Int, Double, Double, Int, Int)] = MapPartitionsRDD[14] at map at <console>:40\r\n",
       "flights2022: org.apache.spark.rdd.RDD[(String, String, String, String, Boolean, Boolean, Int, Double, Double, Int, Int)] = MapPartitionsRDD[15] at map at <console>:41\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "7864b35f90c55bca",
   "metadata": {},
   "source": [
    "## 3. Non‑Optimized Pipeline (Sample)"
   ]
  },
  {
   "cell_type": "code",
   "id": "f76e178194f6b3ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:49:11.647306Z",
     "start_time": "2025-06-04T20:49:08.799406Z"
    }
   },
   "source": [
    "def runYear(\n",
    "        flights: RDD[(String,String,String,String,Boolean,Boolean,Int,Double,Double,Int,Int)],\n",
    "        flightYear: String\n",
    "): RDD[String] = {\n",
    "    \n",
    "    // Average depDelay per airline\n",
    "    val airlineStats = flights\n",
    "        .map { case (_, airline, _, _, _, _, _, depDelay, _, _, _) => (airline, (depDelay, 1))}\n",
    "        .groupByKey()\n",
    "\n",
    "    val arlineMap = airlineStats\n",
    "        .mapValues { iter => iter.foldLeft((0.0, 0)) { case ((sum, cnt), (delay, one)) => (sum + delay, cnt + one)}}\n",
    "\n",
    "    val airlineAvgDelay = arlineMap.mapValues { case (sum, cnt) => sum / cnt }\n",
    "\n",
    "    // Build class\n",
    "    val airlineClass = airlineAvgDelay.mapValues {\n",
    "        case d if d < 5.0  => \"Good\"\n",
    "        case d if d < 15.0 => \"Average\"\n",
    "        case _             => \"Bad\"\n",
    "    }\n",
    "\n",
    "    // Re-key flights by airline\n",
    "    val flightsByAirline = flights\n",
    "        .map { case (date, airline, origin, dest, cancelled, diverted, depTime, depDelay, airTime, year, month) =>\n",
    "            (airline, (date, origin, dest, cancelled, diverted, depTime, depDelay, airTime, year, month))\n",
    "        }\n",
    "\n",
    "    // Join\n",
    "    val taggedFlights = flightsByAirline\n",
    "        .join(airlineClass) \n",
    "        .map { case (_, (flight, cls)) =>\n",
    "            val (date, origin, dest, cancelled, diverted, depTime, depDelay, airTime, year, month) = flight\n",
    "            ((origin, dest, cls), 1)\n",
    "        }\n",
    "\n",
    "    // Count by route+class with groupByKey\n",
    "    val routeClassCounts = (taggedFlights\n",
    "        .groupByKey()\n",
    "        .mapValues(_.size)\n",
    "    )\n",
    "\n",
    "    val perClassLists = routeClassCounts.map {\n",
    "        case ((o, d, c), cnt) => (c, List(((o, d), cnt)))\n",
    "    }\n",
    "\n",
    "    val classOrder = Map(\"Bad\" -> 1, \"Average\" -> 2, \"Good\" -> 3)\n",
    "\n",
    "    // Top5 with reduceByKey\n",
    "    val top5List = perClassLists\n",
    "        .reduceByKey { (l1, l2) => (l1 ++ l2)\n",
    "            .sortBy(-_._2).take(5)\n",
    "        }\n",
    "        .sortBy { case (cls, _) => classOrder(cls) }\n",
    "    \n",
    "    val top5 = top5List\n",
    "        .flatMap { case (cls, list) =>\n",
    "            list.map { case ((o, d), cnt) =>\n",
    "                f\"$cls%-7s | $o%-4s - $d%-4s | Count: $cnt%6d\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "    top5\n",
    "}\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runYear: (flights: org.apache.spark.rdd.RDD[(String, String, String, String, Boolean, Boolean, Int, Double, Double, Int, Int)], flightYear: String)org.apache.spark.rdd.RDD[String]\r\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "adb8a906e8cb1cfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:22:15.048867Z",
     "start_time": "2025-06-04T21:21:37.632547Z"
    }
   },
   "source": [
    "val startNonOpt = System.currentTimeMillis()\n",
    "\n",
    "val res2019 = runYear(flights2019, \"2019\")\n",
    "val res2020 = runYear(flights2020, \"2020\")\n",
    "val res2021 = runYear(flights2021, \"2021\")\n",
    "val res2022 = runYear(flights2022, \"2022\")\n",
    "\n",
    "val allResults = sc.union(res2019, res2020, res2021, res2022)\n",
    "\n",
    "println(s\"\\n=== NON-OPTIMIZED TOP 5 ROUTES PER CLASS ===\")\n",
    "allResults.collect().foreach(println)\n",
    "\n",
    "logJobExecution(startNonOpt, \"NonOptimized-2019-2022\", path_to_output + \"non_optimized_job_execution_times.txt\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NON-OPTIMIZED TOP 5 ROUTES PER CLASS ===\r\n",
      "Bad     | Inc. - EWR  | Count:   3999\r\n",
      "Bad     | LLC d/b/a United Express - DTW  | Count:   2847\r\n",
      "Bad     | LLC d/b/a United Express - ORD  | Count:   2133\r\n",
      "Bad     | Inc. - IAD  | Count:   1891\r\n",
      "Bad     | LLC d/b/a United Express - DEN  | Count:   1589\r\n",
      "Average | LAX  - SFO  | Count:   3420\r\n",
      "Average | SFO  - LAX  | Count:   3238\r\n",
      "Average | LGA  - ORD  | Count:   2942\r\n",
      "Average | ORD  - LGA  | Count:   2877\r\n",
      "Average | LAX  - LAS  | Count:   2569\r\n",
      "Good    | OGG  - HNL  | Count:   1961\r\n",
      "Good    | HNL  - OGG  | Count:   1949\r\n",
      "Good    | HNL  - KOA  | Count:   1401\r\n",
      "Good    | KOA  - HNL  | Count:   1340\r\n",
      "Good    | HNL  - LIH  | Count:   1295\r\n",
      "Average | LLC d/b/a United Express - ORD  | Count:   1574\r\n",
      "Average | Inc. - IAD  | Count:    718\r\n",
      "Average | Inc. - EWR  | Count:    614\r\n",
      "Average | Inc. - IAH  | Count:    349\r\n",
      "Average | LLC d/b/a United Express - EWR  | Count:    260\r\n",
      "Good    | SFO  - LAX  | Count:    889\r\n",
      "Good    | LAX  - SFO  | Count:    883\r\n",
      "Good    | SEA  - PDX  | Count:    777\r\n",
      "Good    | PDX  - SEA  | Count:    748\r\n",
      "Good    | LAS  - LAX  | Count:    705\r\n",
      "Bad     | Inc. - IAH  | Count:   2502\r\n",
      "Bad     | Inc. - DEN  | Count:    667\r\n",
      "Bad     | Inc. - IAD  | Count:    462\r\n",
      "Bad     | FLL  - JFK  | Count:    237\r\n",
      "Bad     | JFK  - FLL  | Count:    218\r\n",
      "Average | LLC d/b/a United Express - ORD  | Count:   1706\r\n",
      "Average | LLC d/b/a United Express - EWR  | Count:   1033\r\n",
      "Average | SFO  - LAX  | Count:    821\r\n",
      "Average | LAS  - LAX  | Count:    810\r\n",
      "Average | LAX  - SFO  | Count:    790\r\n",
      "Good    | HNL  - OGG  | Count:    637\r\n",
      "Good    | OGG  - HNL  | Count:    566\r\n",
      "Good    | ANC  - SEA  | Count:    556\r\n",
      "Good    | PDX  - SEA  | Count:    539\r\n",
      "Good    | SEA  - PDX  | Count:    520\r\n",
      "Bad     | LLC d/b/a United Express - EWR  | Count:   1112\r\n",
      "Bad     | LLC d/b/a United Express - DCA  | Count:    338\r\n",
      "Bad     | DCA  - BOS  | Count:    334\r\n",
      "Bad     | BOS  - DCA  | Count:    319\r\n",
      "Bad     | LLC d/b/a United Express - ORD  | Count:    287\r\n",
      "Average | Inc. - IAH  | Count:   1320\r\n",
      "Average | ORD  - LGA  | Count:    714\r\n",
      "Average | LGA  - ORD  | Count:    700\r\n",
      "Average | SFO  - LAX  | Count:    678\r\n",
      "Average | LAX  - SFO  | Count:    609\r\n",
      "[Wed Jun 04 23:22:14 CEST 2025] Job 'NonOptimized-2019-2022' completed in 33462 ms.\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "startNonOpt: Long = 1749072101535\r\n",
       "res2019: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[337] at flatMap at <console>:89\r\n",
       "res2020: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[357] at flatMap at <console>:89\r\n",
       "res2021: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[377] at flatMap at <console>:89\r\n",
       "res2022: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[397] at flatMap at <console>:89\r\n",
       "allResults: org.apache.spark.rdd.RDD[String] = UnionRDD[398] at union at <console>:54\r\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "3862523f9294b88e",
   "metadata": {},
   "source": [
    "## 4. Optimized Pipeline (Sample)"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6b209a653cd4c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:29:59.083519Z",
     "start_time": "2025-06-04T20:29:57.559131Z"
    }
   },
   "source": [
    "// Union the three year‑specific RDDs\n",
    "val allFlights = sc.union(flights2019, flights2020, flights2021, flights2022).cache()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "allFlights: org.apache.spark.rdd.RDD[(String, String, String, String, Boolean, Boolean, Int, Double, Double, Int, Int)] = UnionRDD[16] at union at <console>:39\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "c0198fc8daf851e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T20:52:00.704410Z",
     "start_time": "2025-06-04T20:51:58.441661Z"
    }
   },
   "source": [
    "def runAllFlights(\n",
    "        allFlights: RDD[(String,String,String,String,Boolean,Boolean,Int,Double,Double,Int,Int)]\n",
    "): Unit = {\n",
    "\n",
    "    // Average depDelay per airline\n",
    "    val airlineAvgDelay = allFlights\n",
    "        .map { case (_, airline, _, _, _, _, _, depDelay, _, _, _) => (airline, (depDelay, 1)) }\n",
    "        .reduceByKey { case ((s1, c1), (s2, c2)) => (s1 + s2, c1 + c2) }\n",
    "        .mapValues { case (sum, cnt) => sum / cnt }\n",
    "    \n",
    "    // Build class\n",
    "    val airlineClass = airlineAvgDelay.mapValues {\n",
    "        case d if d < 5.0  => \"Good\"\n",
    "        case d if d < 15.0 => \"Average\"\n",
    "        case _             => \"Bad\"\n",
    "    }\n",
    "\n",
    "    // Re-key flights by airline\n",
    "    val flightsByAirline = allFlights\n",
    "        .map { case (_, airline, origin, dest, _, _, _, _, _, _, _) =>\n",
    "            (airline, (origin, dest))\n",
    "        }.join(airlineClass)\n",
    "        .map { case (_, ((o, d), cls)) => ((o, d, cls), 1) }\n",
    "\n",
    "    // Count by route+class with reduceByKey\n",
    "    val routeClassCounts = flightsByAirline\n",
    "        .reduceByKey(_ + _)\n",
    "\n",
    "    val perClassLists = routeClassCounts\n",
    "        .map { case ((o, d, cls), cnt) => (cls, ((o, d), cnt))}\n",
    "\n",
    "    val classOrder = Map(\"Bad\" -> 1, \"Average\" -> 2, \"Good\" -> 3)\n",
    "\n",
    "    // Top5 with aggregateByKey\n",
    "    val top5 = perClassLists\n",
    "        .aggregateByKey(List.empty[((String, String), Int)])(\n",
    "            (acc, v) => (acc :+ v)\n",
    "                .sortBy(-_._2)\n",
    "                .take(5),\n",
    "            (acc1, acc2) => (acc1 ++ acc2)\n",
    "                .sortBy(-_._2)\n",
    "                .take(5)\n",
    "        ).mapValues(_.toSeq)\n",
    "\n",
    "    // Top5 print\n",
    "    println(s\"\\n=== OPTIMIZED TOP5 ROUTES PER CLASS ===\")\n",
    "    top5\n",
    "        .flatMap { case (cls, seqRoutes) =>\n",
    "            seqRoutes.map { case ((o, d), cnt) =>\n",
    "                f\"$cls%-7s | $o%-4s - $d%-4s | Count: $cnt%6d\"\n",
    "            }\n",
    "        }\n",
    "        .collect()\n",
    "        .foreach(println)\n",
    "\n",
    "    // Cleanup cached RDDs\n",
    "    allFlights.unpersist()\n",
    "}\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runAllFlights: (allFlights: org.apache.spark.rdd.RDD[(String, String, String, String, Boolean, Boolean, Int, Double, Double, Int, Int)])Unit\r\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T21:22:43.682669Z",
     "start_time": "2025-06-04T21:22:25.824364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val startOpt = System.currentTimeMillis()\n",
    "runAllFlights(allFlights)\n",
    "logJobExecution(startOpt, \"Optimized-2019-2022\", path_to_output + \"optimized_job_execution_times.txt\")"
   ],
   "id": "67ff2e5e6dd4bee3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPTIMIZED TOP5 ROUTES PER CLASS ===\r\n",
      "Good    | HNL  - OGG  | Count:   3481\r\n",
      "Good    | OGG  - HNL  | Count:   3415\r\n",
      "Good    | SEA  - PDX  | Count:   2838\r\n",
      "Good    | PDX  - SEA  | Count:   2767\r\n",
      "Good    | HNL  - KOA  | Count:   2507\r\n",
      "Average | ORD  - LGA  | Count:   4878\r\n",
      "Average | LAX  - SFO  | Count:   4864\r\n",
      "Average | LGA  - ORD  | Count:   4864\r\n",
      "Average | SFO  - LAX  | Count:   4780\r\n",
      "Average | LAX  - LAS  | Count:   4304\r\n",
      "Bad     | LLC d/b/a United Express - ORD  | Count:   5700\r\n",
      "Bad     | Inc. - EWR  | Count:   4818\r\n",
      "Bad     | Inc. - IAH  | Count:   4171\r\n",
      "Bad     | Inc. - IAD  | Count:   3436\r\n",
      "Bad     | LLC d/b/a United Express - DTW  | Count:   3122\r\n",
      "[Wed Jun 04 23:22:43 CEST 2025] Job 'Optimized-2019-2022' completed in 17627 ms.\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "startOpt: Long = 1749072146046\r\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
